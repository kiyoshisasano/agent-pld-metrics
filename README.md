# Phase Loop Dynamicsâ„¢ (PLD) 
*A Runtime Phase Model for Stable Multi-Turn LLM Systems*

![License: Apache-2.0 | CC-BY-4.0](https://img.shields.io/badge/license-Apache%202.0%20%7C%20CC--BY--4.0-blue)
![Status: Active](https://img.shields.io/badge/status-active-brightgreen)

> PLD is not a framework or agent library.  
> It is a runtime governance model for stabilizing multi-turn agents across turns, tools, models, and environments.

---

## ğŸ¯ Is This For You?

PLD becomes relevant when you're building **multi-turn agents** and begin seeing patterns that donâ€™t feel random â€” but donâ€™t feel controllable.

You may be here because your system:

- ğŸ”§ Works in controlled tests, but behaves **unpredictably** in real usage  
- ğŸ” Repeats tool calls or re-enters retry loops without meaningful progress  
- ğŸ§© Recovers from drift once â€” then misaligns later  
- ğŸ”„ Breaks when switching models (GPT â†’ Claude â†’ Llama) despite identical logic  
- ğŸ¤· Feels â€œstable only when untouched,â€ requiring intuition rather than governance  

In other words:

> **Your agent works â€” but not reliably, explainably, or repeatably.**

As systems scale, drift stops being exceptional â€”  
it becomes a predictable characteristic of multi-turn autonomy.  
If your roadmap includes model migration, orchestration, or autonomous decision routing,  
PLD shifts from **"helpful"** to **infrastructure**.

PLD gives you the missing layer:  
a runtime behavioral contract that maintains alignment **across turns â€” not just per response.**

ğŸ‘‰ **If your system *almost works*, you're entering the stage where structured governance becomes necessary.**

---

## ğŸ§  Why PLD Exists â€” 10-Second Summary

Modern multi-turn LLM agents rarely fail because of knowledge gaps â€”  
they fail because alignment **drifts over time**.

PLD introduces a **runtime control loop** that:

- Detects drift early  
- Repairs behavior  
- Confirms alignment before continuing  

```
Drift â†’ Repair â†’ Reentry â†’ Continue â†’ Outcome
```

---

### ğŸ“ High-Level Runtime Model (Visual Summary)

> A compact view of the runtime loop, metrics integration, and conceptual role of PLD.

<img src="./README_model.svg" width="100%" />

---

## ğŸ§© What PLD *Is* â€” In 30 Seconds


PLD is:

- A **runtime phase model** for interaction stability  
- A structured method for **drift detection and repair**
- A **behavioral governance layer**, not a model prompt or product
- **Observable and measurable** â€” compatible with telemetry and evaluation
- Implementation-agnostic: works with tool agents, retrieval systems, planners, and chat models  

> PLD governs **how behavior evolves over turns**, not how a single output is generated.

---

## ğŸš€ Who Uses PLD

| Role | Value |
|------|-------|
| **LLM / Agent Engineers** | Reduced cascade errors, fewer resets |
| **Interaction & UX Designers** | Predictable repair and alignment signaling |
| **AgentOps & Evaluation Teams** | Observable behavioral diagnostics and metrics |

---

## ğŸ§­ The PLD Runtime Loop

| Phase | Purpose | Signals |
|-------|---------|---------|
| **Drift** | Detect divergence from task or shared reality | tool errors, contradiction, missing context |
| **Repair** | Soft/hard correction | clarification, reset, constraint restatement |
| **Reentry** | Confirm restored alignment | checkpoint, summarization |
| **Continue** | Resume execution | next step |
| **Outcome** | End state | complete / partial / failed / abandoned |

> Framework-agnostic: supports LangGraph, Assistants API, AutoGen, Swarm, Rasa, or custom orchestrators.

---

## ğŸ“ˆ Runtime Model Diagram

```mermaid
flowchart LR
    Start([Turn])
    Drift{Drift?}
    Repair["Repair\n(soft/hard)"]
    Reentry["Reentry\n(confirm)"]
    Continue[Continue]
    Outcome[(Outcome)]

    Start --> Drift
    Drift -->|No| Continue
    Drift -->|Yes| Repair --> Reentry -->|Aligned| Continue --> Outcome --> Start
    Reentry -->|Not aligned| Drift
```

Full reference: `/docs/model_diagram.md`

---

## ğŸ†š Before vs After PLD

| Without PLD | With PLD |
|-------------|----------|
| Silent brittle failures | Explicit repair and confirmation |
| Repeated invalid tool calls | Controlled retry + fallback |
| Lost context | Structured reentry checkpoints |
| Unpredictable user experience | Observable, governable behavior |

---

### ğŸ— Optional: Architectural Perspective

ğŸ“„ `/docs/architecture_layers.md`  
A higher-level view for teams mapping PLD into large orchestration stacks.

---

### ğŸ Quickstart â€” Run PLD in Under 10 Seconds

Before diving into the full documentation, you can **experience PLD behavior immediately**.

PLD is a telemetry-first paradigm.

Every turn produces measurable behavioral events aligned to:

- `quickstart/metrics/schemas/pld_event.schema.json`
- `quickstart/metrics/schemas/metrics_schema.yaml`

This enables governance not by intuition â€” but by data.


#### Step 1 â€” Run the Teaching Runtime (Recommended First)

```bash
python quickstart/hello_pld_runtime.py
```

Try custom input:
```bash
python quickstart/hello_pld_runtime.py "Can we switch topics and talk about cooking?"
```

Run all example scenarios:
```bash
python quickstart/hello_pld_runtime.py --examples
```

> PLD is best understood through interaction â€” not just by reading.
> This script demonstrates the core runtime loop:
> Drift â†’ Repair â†’ Reentry â†’ Continue â†’ Outcome
> (in a minimal mock runtime environment)

---

#### Step 2 â€” Run the Real Runtime Engine

Once the lifecycle makes sense conceptually, you can execute the actual runtime controller:

```bash
python quickstart/run_minimal_engine.py
```

- Uses real ingestion, controller, and enforcement logic

- Simulates a drift condition (e.g., empty RAG result)

- Outputs policy decisions, trace IDs, and next-action recommendations

> ğŸ› ï¸ This verifies PLD is installed and running as a real runtime, not just a conceptual demonstration.

---

#### ğŸ“Š Optional Step â€” Verify Metrics Locally
Once you've run the runtime and seen PLD behavior,
you can also measure it using the included demo dataset:
```bash
python quickstart/metrics/verify_metrics_local.py
```

- This will calculate sample operational metrics such as:
- PRDR â€” Post-Repair Drift Recurrence
- VRL â€” Visible Repair Load
- MRBF â€” Mean Repairs Before Failover
- FR â€” Failover Rate

â¡ Detailed guide: `quickstart/metrics/README_metrics.md`

---
 
For deeper usage patterns, continue with:  
â¡ï¸` quickstart/README_quickstart.md` 

---

### ğŸ“Š Operational Dashboard (Preview)

Once PLD is running and metrics are emitted, the system becomes observable â€” not just executable.

<p align="center">
  <img src="./docs/assets/dashboard_mockup.svg" width="60%" />
</p>

> This dashboard represents the **end-state goal**: a stable monitoring layer that makes system behavior measurable and governable â€” not assumed.

This visualization corresponds to the five operational metrics defined in:

â¡ `docs/07_pld_operational_metrics_cookbook.md`

| Metric | What it answers |
|--------|----------------|
| **PRDR** | Do repairs *stick*, or does drift recur? |
| **REI** | Are repairs *worth the cost*? |
| **VRL** | Does the system *feel stable* to users? |
| **FR** | How often does the system reach failure fallback? |
| **MRBF** | How long does the system try before giving up? |

PLD is designed as a closed feedback loop:

Runtime â†’ Logging â†’ Metrics â†’ Dashboard â†’ Policy Adjustment â†’ Improved Behavior â†’ Runtime

---

#### When this dashboard becomes useful

| Stage | Value |
|-------|-------|
| **Early prototyping** | Optional â€” behavior is still unpredictable |
| **Beta rollout (10â€“200 users)** | ğŸ”¥ Most value â€” detects convergence vs fragility |
| **Production** | Used for regression tracking and release gating |
| **Mature system** | Moves from real-time monitoring â†’ weekly health check |

> The goal is not to chase perfect metrics â€”  
> but to **make runtime behavior visible, measurable, and governable.**

---


## ğŸ“‚ Repository Overview

```
/quickstart     â€” Learning path + implementation patterns (start here)
/pld_runtime    â€” Reference runtime (optional)
/docs           â€” Taxonomy, conceptual model, reference material
/analytics      â€” Benchmark datasets + case studies
/field          â€” Collaboration playbooks and adoption patterns
```

â¡ Full structure: `/docs/repo_structure.md`

---

## ğŸ“ Operational Metrics

Once PLD is active in a system, evaluation may include:

- Drift frequency
- Repair efficiency (soft vs hard)
- Reentry confirmation success
- Stability vs latency trade-offs
- Outcome completion distribution

Full operational framework including PRDR, REI, VRL and evaluation workflow:  
ğŸ‘‰ `/docs/07_pld_operational_metrics_cookbook.md`

---

## ğŸ§ª Practical Adoption Path

| Step | Folder | Purpose |
|------|--------|---------|
| **1** | `/quickstart/overview/` | Understand the runtime loop |
| **2** | `/quickstart/operator_primitives/` | Apply operator logic |
| **3** | `/quickstart/patterns/` | Modular behavior patterns |
| **4** | `/quickstart/patterns/04_integration_recipes/` | **Runnable reference examples** |
| **5** | `/quickstart/metrics/` | Log drift â†’ repair â†’ reentry â†’ outcome |
| **6** | `/analytics/` | Compare results against evaluated traces |
| **7** | `/docs/07_pld_operational_metrics_cookbook.md` | Apply runtime metrics to optimize repairs and stability |

---

### ğŸ§© Runnable Integration Recipes

```
quickstart/patterns/04_integration_recipes/
```

These reference examples are:

| Property | Meaning |
|----------|---------|
| ğŸ§ª Runnable | Executable locally (no infra required) |
| ğŸ” Observable | Emits structured PLD signals |
| ğŸ“ˆ Measurable | Compatible with metrics cookbook |
| ğŸ§± Modular | Works with memory, tools, or RAG systems |

---

### â–¶ Minimal Conceptual Example

This illustrates the phase loop logic â€” not a runnable implementation.

```python
# Conceptual pseudo-implementation

phase = detect_drift(turn)

if phase is DRIFT:
    turn = repair(turn)
    phase = REPAIR

if phase is REPAIR:
    if confirm_alignment(turn):
        phase = CONTINUE
    else:
        phase = DRIFT
```

> Actual implementation depends on the orchestration environment.

---

## ğŸ“Š Evidence Layer

Validated through:

- MultiWOZ 2.4 (200 annotated dialogs)
- Real tool-enabled agents
- Applied SaaS support case studies
- Field PoCs

See: `/analytics/`

---

## ğŸ”Œ Integrations

Compatible with:

- LangGraph
- Assistants API
- Swarm
- Rasa
- ReAct-style planners
- Custom orchestration pipelines

No required framework â€” only the **loop semantics**.

---

## ğŸ¤ Contribution & Collaboration

Contributions are welcome, especially:

- Runtime bridges and adapters  
- Evaluation datasets and traces  
- Operational repair heuristics  
- Metrics dashboards  

For shared PoCs or partnership work â†’ see `/field/`.

---

## ğŸ“ When PLD Applies

Best suited when:

âœ” Multi-turn workflows  
âœ” Tools, retrieval, memory, or planning  
âœ” Recovery matters more than one-shot accuracy  

Less relevant when:

âš  Single-turn answers  
âš  Fully deterministic scripted flows  

---

---

## ğŸ§­ Metadata & Manifest System (How Components Are Described)

PLD is designed for collaboration â€” especially in environments where multiple teams,
implementations, or runtime modules evolve over time.

To support this, the repository includes a lightweight metadata system that makes
components **discoverable, traceable, and machine-checkable** without restricting experimentation.

This system consists of three parts:

| Purpose                             | File                             |
| ----------------------------------- | -------------------------------- |
| Specification (the rules)           | `meta/METADATA_MANIFEST_SPEC.md` |
| Reference example                   | `meta/manifest.example.yaml`     |
| Active metadata for this repository | `manifest.yaml`                  |

The manifest format is intentionally simple and may evolve as integrations and
field usage mature.

---

### ğŸ“¦ What Belongs in the Manifest?

Any artifact that participates in runtime behavior, evaluation, documentation,
or integration can be listed in the manifest â€” including:

* runtime modules
* schemas and metrics
* documentation assets
* examples and learning paths
* experimental work

Each entry includes:

* a stable `component_id`
* controlled vocabulary fields (`kind`, `status`, `authority_level`)
* a short human-readable purpose

Full details: `meta/METADATA_MANIFEST_SPEC.md`.

---

### ğŸ›  Validating the Manifest

A helper script is included for contributors and teams automating runtime governance.

```bash
python validate_manifest.py
```

Validation levels:

| Level | Meaning                                               |
| ----- | ----------------------------------------------------- |
| `L0`  | Structural only â€” useful for exploration              |
| `L1`  | Format + vocabulary enforcement (default)             |
| `L2`  | File existence + optional alignment with code headers |

Example:

```bash
python validate_manifest.py --level L2
```

This allows gradual adoption â€” from prototype â†’ controlled collaboration â†’ automated CI enforcement.

---

### ğŸ¤ Contributing Metadata

When adding new runtime files, documents, or integration artifacts:

1. Add or update an entry in `manifest.yaml`
2. Run the validator:

```bash
python validate_manifest.py --level L1
```

3. Commit changes as part of the same PR.

> Metadata is not bureaucracy â€” it is a map.
> It helps others understand *what exists*, *why it exists*, and *how stable it is.*

---


## ğŸ“œ License

This project uses a dual-license model:

| Scope | License |
|--------|---------|
| Runtime and code | Apache 2.0 |
| Documentation and methodology | CC BY 4.0 |  

Full details: `LICENSES/LICENSES.md`  
Trademark usage: `LICENSES/TRADEMARK_POLICY.md`

For enterprise licensing or collaboration:  
ğŸ“© deepzenspace[at]gmail.com

---

"Phase Loop Dynamics" and "PLD" are claimed as common law trademarks of Kiyoshi Sasano.  
Use of the marks is governed by the project's trademark policy.

Maintainer: **Kiyoshi Sasano** Copyright Â© 2025

---

> **PLD is behavioral infrastructure â€”  
it ensures alignment persists *across interaction*,  
not just at initialization.**
